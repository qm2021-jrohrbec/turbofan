{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "executive-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cognitive-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTFData(path = \"dataset\", sets = [1,2,3,4], testing = True, maxrul = None):\n",
    "    # load turbofan data\n",
    "    \n",
    "    # id, delta time, settings, sensors\n",
    "    colnames = ['id', 'dt',\n",
    "                    'set1', 'set2', 'set3',\n",
    "                        's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', \n",
    "                        's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "    \n",
    "    if 1 in sets:\n",
    "        train1 = pd.read_table(f\"{path}/train_FD001.txt\", header=None, delim_whitespace=True)\n",
    "        if testing:\n",
    "            test1 = pd.read_table(f\"{path}/test_FD001.txt\", header=None, delim_whitespace=True)\n",
    "            rul1 = pd.read_table(f\"{path}/RUL_FD001.txt\", header=None, delim_whitespace=True)\n",
    "    if 2 in sets:\n",
    "        train2 = pd.read_table(f\"{path}/train_FD002.txt\", header=None, delim_whitespace=True)\n",
    "        if testing:\n",
    "            test2 = pd.read_table(f\"{path}/test_FD002.txt\", header=None, delim_whitespace=True)\n",
    "            rul2 = pd.read_table(f\"{path}/RUL_FD002.txt\", header=None, delim_whitespace=True)\n",
    "    if 3 in sets: \n",
    "        train3 = pd.read_table(f\"{path}/train_FD003.txt\", header=None, delim_whitespace=True)\n",
    "        if testing:\n",
    "            test3 = pd.read_table(f\"{path}/test_FD003.txt\", header=None, delim_whitespace=True)\n",
    "            rul3 = pd.read_table(f\"{path}/RUL_FD003.txt\", header=None, delim_whitespace=True)\n",
    "    if 4 in sets:\n",
    "        train4 = pd.read_table(f\"{path}/train_FD004.txt\", header=None, delim_whitespace=True)\n",
    "        if testing:\n",
    "            test4 = pd.read_table(f\"{path}/test_FD004.txt\", header=None, delim_whitespace=True)\n",
    "            rul4 = pd.read_table(f\"{path}/RUL_FD004.txt\", header=None, delim_whitespace=True)\n",
    "    \n",
    "    trainframes = []\n",
    "    testframes = []\n",
    "    \n",
    "    maxidtr = 0\n",
    "    maxidte = 0\n",
    "    lentr = 0\n",
    "    lente = 0\n",
    "\n",
    "    getRul = lambda col: col[::-1] - 1 # reverses order, - 1 so that it ends with 0\n",
    "    \n",
    "    getFrac = lambda col: col / col.max() # calculates fraction\n",
    "    \n",
    "    for (train, test, rul) in [('train' + str(i), 'test' + str(i), 'rul' + str(i)) for i in sets]:\n",
    "        \n",
    "        train = eval(train)\n",
    "        \n",
    "        train.columns = colnames\n",
    "        \n",
    "        # create rul for training\n",
    "        train['rul'] = train[['id', 'dt']].groupby('id').transform(getRul)\n",
    "        if maxrul is not None:\n",
    "            train.loc[train.rul > maxrul, 'rul'] = maxrul\n",
    "        train['rulfrac'] = train[['id','rul']].groupby('id').transform(getFrac)\n",
    "        \n",
    "        # update index and make id unique\n",
    "        train['id'] = train['id'] + maxidtr\n",
    "        maxidtr = train['id'].max()\n",
    "        \n",
    "        train.index = range(lentr, lentr + len(train))\n",
    "        lentr = lentr + len(train)\n",
    "        \n",
    "        trainframes.append(train)\n",
    "        \n",
    "        if testing:\n",
    "            test = eval(test)\n",
    "            rul = eval(rul)\n",
    "            \n",
    "            test.columns = colnames\n",
    "            \n",
    "            # create rul for testing\n",
    "            test['rul'] = test[['id', 'dt']].groupby('id').transform(getRul)\n",
    "            for j in test['id'].unique():\n",
    "                if (j - 1) in rul.index:\n",
    "                    n = len(test[test['id'] == j]['rul'])\n",
    "                    temp = rul[0][j - 1].repeat(n) # true rul\n",
    "                    test.loc[test['id'] == j, 'rul'] = test.loc[test['id'] == j, 'rul'] + temp # add true rul\n",
    "            test['rulfrac'] = test[['id','rul']].groupby('id').transform(getFrac)\n",
    "            \n",
    "            # update index and make id unique\n",
    "            test['id'] = test['id'] + maxidte\n",
    "            maxidte = test['id'].max()\n",
    "            \n",
    "            test.index = range(lente, lente + len(test))\n",
    "            lente = lente + len(test)\n",
    "            \n",
    "            testframes.append(test)\n",
    "        \n",
    "    train = pd.concat(trainframes)\n",
    "    \n",
    "    if testing:\n",
    "        test = pd.concat(testframes)\n",
    "        return train, test\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dynamic-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltS(df, s, mod = 10):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    counter = 0\n",
    "    for i in d['id'].unique():\n",
    "        counter += 1\n",
    "        if counter % mod == 0:\n",
    "            plt.plot('rul', s, data = df[df['id'] == i])\n",
    "    plt.xlim(375, 0)\n",
    "    plt.xticks(np.arange(0, 400, 25))\n",
    "    plt.ylabel(s)\n",
    "    plt.xlabel('Remaining Use fulLife')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lyric-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltSC(data, s, c, mod = 10):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    df = data.copy()\n",
    "    df = df[df[c] == 1]\n",
    "    counter = 0\n",
    "    for i in df['id'].unique():\n",
    "        counter += 1\n",
    "        if counter % mod == 0:\n",
    "            plt.plot('rul', s, data = df[df['id'] == i])\n",
    "    plt.xlim(500, 0)\n",
    "    plt.xticks(np.arange(0, 525, 25))\n",
    "    plt.ylabel(s)\n",
    "    plt.xlabel('Remaining Use fulLife')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "genetic-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagData(data, lagsize = 5, dropna = False):\n",
    "    # creates lagged data frame\n",
    "    \n",
    "    colnames = data.columns\n",
    "    \n",
    "    tempframe =[]\n",
    "    \n",
    "    for i, d in data.groupby('id'):\n",
    "        temp = {} # new dict\n",
    "        for name in colnames:\n",
    "            temp[name] = d[name]\n",
    "            if name not in ['id','dt','rul','rulfrac']:\n",
    "                for j in range(lagsize):\n",
    "                    temp['%s_lg_%d' %(name, j + 1)] = d[name].shift(j + 1)\n",
    "        tempframe.append(pd.DataFrame(temp, index = d.index))            \n",
    "    df = pd.concat(tempframe)\n",
    "    if dropna:\n",
    "        df = df.dropna()\n",
    "        df.index = range(len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def aggregateCategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acceptable-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSettings(data):\n",
    "    # from prior explorataion\n",
    "    setting_names = ['set1', 'set2', 'set3']\n",
    "    settings_df = data[setting_names].copy()\n",
    "    settings_df['set1'] = settings_df['set1'].round()\n",
    "    settings_df['set2'] = settings_df['set2'].round(decimals=2)\n",
    "    \n",
    "    data['c1'] = 0\n",
    "    data['c2'] = 0\n",
    "    data['c3'] = 0\n",
    "    data['c4'] = 0\n",
    "    data['c5'] = 0\n",
    "    data['c6'] = 0\n",
    "\n",
    "    c = 0\n",
    "    for i, d in settings_df.groupby(by = ['set1','set2','set3']):\n",
    "        c += 1\n",
    "        data.loc[d.index,['c' + str(c)]] = 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Settings allgemein? (ueberhaupt sinnvoll?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "imperial-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cScale(dftrain, dftest, sensors):\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    for c in ['c1', 'c2', 'c3', 'c4', 'c5', 'c6']:\n",
    "        scaler.fit(dftrain.loc[dftrain[c] == 1, sensors])\n",
    "        \n",
    "        dftrain.loc[dftrain[c] == 1, sensors] = scaler.transform(dftrain.loc[dftrain[c] == 1, sensors])\n",
    "        \n",
    "        dftest.loc[dftest[c] == 1, sensors] = scaler.transform(dftest.loc[dftest[c] == 1, sensors])\n",
    "    \n",
    "    return dftrain, dftest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
